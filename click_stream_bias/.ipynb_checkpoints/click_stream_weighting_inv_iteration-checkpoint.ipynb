{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import sys\n",
    "import os\n",
    "%pylab notebook\n",
    "lib_path = '/home/fgeigl/navigability_of_networks'\n",
    "sys.path.append(lib_path)\n",
    "lib_path = '/home/fgeigl/navigability_of_networks/tools'\n",
    "sys.path.append(lib_path)\n",
    "import network_matrix_tools\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, diags, eye\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from collections import Counter\n",
    "import operator\n",
    "from sklearn.preprocessing import normalize\n",
    "import numba\n",
    "from joblib import Parallel, delayed\n",
    "from math import sqrt\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((loader['data'], loader['indices'], loader['indptr']), shape=loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = load_sparse_csr('/opt/datasets/wiki_clickstream/adjacency_clickstream_network_largest_component.npz')\n",
    "B = load_sparse_csr('/opt/datasets/wiki_clickstream/clickstream_network_transition_bias_largest_component.npz')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('A:', type(A), A.shape)\n",
    "print('B:', type(B), B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, labels = connected_components(A + B, directed=True, connection='strong', return_labels=True)\n",
    "label_counts = Counter(labels)\n",
    "largest_label, num_nodes = max(label_counts.items(), key=operator.itemgetter(1))\n",
    "print('largest component contains', num_nodes, 'nodes', '(', num_nodes/A.shape[0], ')')\n",
    "if num_nodes != A.shape[0]:\n",
    "    label_filt = labels == largest_label\n",
    "    A = A[label_filt, :][:, label_filt]\n",
    "    B = B[label_filt, :][:, label_filt]\n",
    "print('A:', type(A), A.shape, A.nnz/(np.power(A.shape[0],2)))\n",
    "print('B:', type(B), B.shape, B.nnz/(np.power(B.shape[0],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stat_dist_power_iter(M, max_iter = 1e5, print_step=10, early_stopping = 500, precision=10, init_vec = None, n_jobs=40, eigval=1.):\n",
    "    print('\\tnormalize...', end='')\n",
    "    sys.stdout.flush()\n",
    "    max_iter = int(max_iter)\n",
    "    M = M.astype(np.float)\n",
    "    P = M.dot(diags(1. / np.array(M.sum(axis=0), dtype=np.float).flatten()))\n",
    "    if init_vec is None:\n",
    "        pi_vec = np.ones(P.shape[0], dtype=np.float) / P.shape[0]\n",
    "    else:\n",
    "        pi_vec = init_vec.astype(np.float)\n",
    "    print('done. ', type(pi_vec), pi_vec.dtype, type(P), P.dtype)\n",
    "    sys.stdout.flush()\n",
    "    diff = list()\n",
    "    best_pi = None\n",
    "    best_norm = -1\n",
    "    best_diff = 100\n",
    "    no_improve = 0\n",
    "    print_row = list()\n",
    "    precision = int(round(precision))\n",
    "    atol = np.power(1e1, -precision)\n",
    "    last_diff = 100\n",
    "    print('\\tstart power iterations. max. iterations:', max_iter)\n",
    "    sys.stdout.flush()\n",
    "    comp_times = list()\n",
    "    start = datetime.datetime.now()\n",
    "    identiy = eye(P.shape[0])\n",
    "    P_solve = P - (eigval * identiy)\n",
    "    pi_vec, norm = normalize(pi_vec)\n",
    "    for i in range(1, max_iter + 1):\n",
    "        now = datetime.datetime.now()\n",
    "        comp_times.append((now-start).total_seconds())\n",
    "        comp_times = comp_times[-10:]\n",
    "        avg_iter_time = sum(comp_times)/len(comp_times)\n",
    "        pi_vec, last_vec = spsolve(P_solve, pi_vec), pi_vec\n",
    "        # print(pi_vec)\n",
    "        pi_vec, norm = normalize(pi_vec)\n",
    "        current_diff = np.absolute(last_vec - pi_vec).max()\n",
    "        if current_diff < atol:\n",
    "            print('\\nneeded', i, 'iterations')\n",
    "            print('last diff:', (\" %.\" + str(precision) + 'f') % current_diff)\n",
    "            print('\\nlargest eigval:', (\" %.\" + str(precision) + 'f') % norm)\n",
    "            assert len(pi_vec) == P.shape[0]\n",
    "            return pi_vec\n",
    "        improvement = current_diff - best_diff\n",
    "        if improvement < 0:\n",
    "            best_iter = i\n",
    "            no_improve = 0\n",
    "            best_diff = current_diff\n",
    "            print_row.append('-')\n",
    "        else:\n",
    "            print_row.append('+')\n",
    "            if no_improve == 0:\n",
    "                best_pi = last_vec.copy()\n",
    "            no_improve += 1\n",
    "        diff.append(current_diff)\n",
    "        time_remain = (current_diff / improvement) * avg_iter_time\n",
    "        trend = sum(diff[-int(early_stopping/2):]) - sum(diff[-early_stopping:-int(early_stopping/2)])\n",
    "        trend_print = ('v' if trend < 0 else '^') if len(diff) > early_stopping else ' '\n",
    "        print_row = print_row[-print_step:]\n",
    "        print('\\r', '[' + (''.join(print_row)).rjust(print_step) + ']', \n",
    "              str(i).rjust(len(str(max_iter)),'0'), \n",
    "              (\"%.\" + str(precision) + 'f') % current_diff, \n",
    "              trend_print,\n",
    "              (\" %.\" + str(precision) + 'f') % improvement, \n",
    "              (\"%.3f\" % avg_iter_time), 'sec/it', \n",
    "              'min. remain:', datetime.timedelta(seconds=int(time_remain)), end='')\n",
    "        sys.stdout.flush()\n",
    "        if no_improve >= early_stopping and trend > 0:\n",
    "            print('\\nearly stopping triggert.')\n",
    "            break\n",
    "    print('\\ndid not converge within', i, 'iterations.')\n",
    "    print('\\t', 'return best pi. iteration:', best_iter)\n",
    "    print('\\tlargest eigval:', \"%.15f\" % best_norm)\n",
    "    assert len(best_pi) == P.shape[0]\n",
    "    return best_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_fname = 'click_stream_results_poweriter_inv_it.df'\n",
    "time_df_fname = 'click_stream_times_poweriter_inv_it.df'\n",
    "try:\n",
    "    df = pd.read_pickle(df_fname)\n",
    "    times = pd.read_pickle(time_df_fname)\n",
    "    print('loaded stored data:', df.columns)\n",
    "except:\n",
    "    print('init new data')\n",
    "    df = pd.DataFrame()\n",
    "    times = pd.Series()\n",
    "\n",
    "# stat_dist_power_iter(A)\n",
    "A = A.astype(np.longdouble)\n",
    "B = B.astype(np.longdouble)\n",
    "\n",
    "if 'A_sd' not in df.columns:\n",
    "    start = datetime.datetime.now()\n",
    "    #_, df['A_sd'] = network_matrix_tools.calc_entropy_and_stat_dist(A, method='EV', smooth_bias=False, calc_entropy_rate=False)\n",
    "    df['A_sd'] = np.nan\n",
    "    df['A_sd'] = df['A_sd'].astype(np.longdouble)\n",
    "    df['A_sd'] = stat_dist_power_iter(A)\n",
    "    times.loc['A_sd'] = datetime.datetime.now() - start\n",
    "    print(datetime.datetime.now() - start)\n",
    "init_vec = df['A_sd'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for beta in [1., 0.75, 0.5, 0.25, 0.1, 0.05, 0.01, 0.005, 0.001]:\n",
    "    col_name = 'beta_' + str(beta)\n",
    "    if col_name not in df.columns:\n",
    "        print('calc beta:', beta)\n",
    "        print('\\t', datetime.datetime.now())\n",
    "        start = datetime.datetime.now()\n",
    "        # _, df[col_name] = network_matrix_tools.calc_entropy_and_stat_dist((beta * A) + B.T, method='EV', smooth_bias=False, calc_entropy_rate=False)\n",
    "        df[col_name] = np.nan\n",
    "        df[col_name] = df[col_name].astype(np.longdouble)\n",
    "        df[col_name] = stat_dist_power_iter((beta * A) + B.T, init_vec = init_vec)\n",
    "        print(df[col_name].dtype)\n",
    "        times.loc[col_name] = datetime.datetime.now() - start\n",
    "        print('\\ttook', datetime.datetime.now() - start, '\\n')\n",
    "        df.to_pickle(df_fname)\n",
    "        times.to_pickle(time_df_fname)\n",
    "    else:\n",
    "        print('calc beta:', beta, 'already cached')\n",
    "        print('\\ttook:', times.loc[col_name])\n",
    "    init_vec = df[col_name].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('pearson:')\n",
    "print(df.corr(method='pearson').iloc[0])\n",
    "print('spearman:')\n",
    "print(df.corr(method='spearman').iloc[0])\n",
    "#print('kendall:')\n",
    "#print(df.corr(method='kendall').iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_key(name):\n",
    "    val = name.rsplit('_', 1)[-1]\n",
    "    try:\n",
    "        return float(val)\n",
    "    except:\n",
    "        return 100.\n",
    "\n",
    "sorted_cols = sorted(df.columns, key=sort_key)\n",
    "df = df[sorted_cols]\n",
    "df.to_pickle(df_fname)\n",
    "times.to_pickle(time_df_fname)\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
