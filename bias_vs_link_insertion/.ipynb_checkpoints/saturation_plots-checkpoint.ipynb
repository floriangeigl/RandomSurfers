{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "append /home/fgeigl/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.colors import colorConverter\n",
    "%pylab notebook\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import traceback\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import string\n",
    "from graph_tool.all import *\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import powerlaw\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "lib_path = '/home/fgeigl/'\n",
    "print('append', lib_path)\n",
    "sys.path.append(lib_path)\n",
    "import tools.mpl_tools as plt_tools\n",
    "# import seaborn\n",
    "matplotlib.rcParams.update({'font.size': 25})\n",
    "matplotlib.rcParams['xtick.major.pad'] *= 2\n",
    "matplotlib.rcParams['ytick.major.pad'] *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daserste\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/daserste.gt/daserste.gt_bs0002_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/daserste.gt/daserste.gt_bs0003_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/daserste.gt/daserste.gt_bs0005_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/daserste.gt/daserste.gt_bs0010_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/daserste.gt/daserste.gt_bs0015_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/daserste.gt/daserste.gt_bs0030_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/daserste.gt/daserste.gt_bs0060_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/daserste.gt/daserste.gt_bs0100_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/daserste.gt/daserste.gt_bs0150_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/daserste.gt/daserste.gt_bs0200_preprocessed.df\n",
      "tvthek_orf\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/tvthek_orf.gt/tvthek_orf.gt_bs0002_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/tvthek_orf.gt/tvthek_orf.gt_bs0003_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/tvthek_orf.gt/tvthek_orf.gt_bs0005_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/tvthek_orf.gt/tvthek_orf.gt_bs0010_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/tvthek_orf.gt/tvthek_orf.gt_bs0015_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/tvthek_orf.gt/tvthek_orf.gt_bs0030_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/tvthek_orf.gt/tvthek_orf.gt_bs0060_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/tvthek_orf.gt/tvthek_orf.gt_bs0100_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/tvthek_orf.gt/tvthek_orf.gt_bs0150_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/tvthek_orf.gt/tvthek_orf.gt_bs0200_preprocessed.df\n",
      "wiki4schools\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/wiki4schools.gt/wiki4schools.gt_bs0002_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/wiki4schools.gt/wiki4schools.gt_bs0003_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/wiki4schools.gt/wiki4schools.gt_bs0005_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/wiki4schools.gt/wiki4schools.gt_bs0010_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/wiki4schools.gt/wiki4schools.gt_bs0015_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/wiki4schools.gt/wiki4schools.gt_bs0030_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/wiki4schools.gt/wiki4schools.gt_bs0060_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/wiki4schools.gt/wiki4schools.gt_bs0100_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/wiki4schools.gt/wiki4schools.gt_bs0150_preprocessed.df\n",
      "\t /home/fgeigl/navigability_of_networks/output/opt_link_man/wiki4schools.gt/wiki4schools.gt_bs0200_preprocessed.df\n"
     ]
    }
   ],
   "source": [
    "def find_files(base_dir, file_ending):\n",
    "    res = list()\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if not root.endswith('/'):\n",
    "            root += '/'\n",
    "        res.extend([root + i for i in filter(lambda x: x.endswith(file_ending), files)])\n",
    "    return sorted(res)\n",
    "\n",
    "base_dir = '/home/fgeigl/navigability_of_networks/output/opt_link_man/'\n",
    "df_files = filter(lambda x: 'preprocessed' in x, find_files(base_dir,'.df'))\n",
    "debug = False\n",
    "plots_dir = base_dir + '/plots/'\n",
    "if not os.path.isdir(plots_dir):\n",
    "    os.makedirs(plots_dir)\n",
    "\n",
    "\n",
    "data_sets = defaultdict(set)\n",
    "for f in df_files:\n",
    "    dset = f.rsplit('/',1)[-1].split('.gt',1)[0]\n",
    "    data_sets[dset].add(f)\n",
    "\n",
    "for key, val in data_sets.iteritems():\n",
    "    print(key)\n",
    "    for i in sorted(val):\n",
    "        print('\\t',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all dfs for wiki4schools ..........\n",
      "sample-sizes [0.01, 0.025000000000000001, 0.050000000000000003, 0.074999999999999997, 0.10000000000000001, 0.125, 0.14999999999999999, 0.17499999999999999, 0.20000000000000001]\n",
      "bias-strengths [2, 3, 5, 10, 15, 30, 60]\n",
      "read all dfs for tvthek_orf ...."
     ]
    }
   ],
   "source": [
    "max_sample_size = 0.21\n",
    "data_dict = dict()\n",
    "for key, val in sorted(data_sets.iteritems(), key=operator.itemgetter(0), reverse=True)[:(1 if debug else len(data_sets))]:\n",
    "    df_all = None\n",
    "    print('read all dfs for', key, end=' ')\n",
    "    sys.stdout.flush()\n",
    "    for df_file in sorted(val):\n",
    "        print('.', end='')\n",
    "        bs = int(df_file.rsplit('_bs',1)[-1].split('_',1)[0])\n",
    "        if bs > 200:\n",
    "            continue\n",
    "        df = pd.read_pickle(df_file)\n",
    "        # print(sorted(df.columns))\n",
    "        df = df[['sample-size', 'stat_dist_com_sum', 'orig_stat_dist_sum', 'add_top_block_links_fair']]        \n",
    "        df['sample-size'] = np.round(df['sample-size'], 3)\n",
    "        df = df[map(lambda x: x < max_sample_size ,df['sample-size'])]\n",
    "        df['bias-strength'] = bs\n",
    "        if df_all is None:\n",
    "            df_all = df.copy()\n",
    "        else:\n",
    "            df_all = pd.concat([df_all, df])\n",
    "    # print(df_all.head())\n",
    "    data_dict[key] = df_all.copy()\n",
    "    print('\\nsample-sizes', sorted(set(df_all['sample-size'])))\n",
    "    print('bias-strengths', sorted(set(df_all['bias-strength'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_sizes = [0.01, 0.1, 0.2]\n",
    "ds_names_conv = {'wiki4schools':'W4S', 'tvthek_orf':'ORF', 'daserste':'DEM'}\n",
    "\n",
    "colors = ['#e41a1c','#377eb8','#4daf4a']\n",
    "markers = \"ov^<>sp*+x\"\n",
    "line_styles = ['--', '-', ':']\n",
    "matplotlib.rcParams.update({'font.size': 25})\n",
    "\n",
    "for method in ['link_inseration', 'bias']:\n",
    "    fig, ax = plt.subplots()\n",
    "    print('Method:', method)\n",
    "    measure = 'add_top_block_links_fair' if method == 'link_inseration' else 'stat_dist_com_sum'\n",
    "    for idx, (ds_name, val) in enumerate(sorted(data_dict.iteritems(), key=operator.itemgetter(0), reverse=True)):\n",
    "        # fig, ax = plt.subplots()\n",
    "        c = colors[idx]\n",
    "        for jdx, (key, df) in enumerate(val[map(lambda x: x in sample_sizes ,val['sample-size'])].groupby('sample-size')):\n",
    "            filt_df = df[['bias-strength', measure]]\n",
    "            grp_df = filt_df.groupby('bias-strength')\n",
    "            grp_mean = grp_df.mean()\n",
    "            grp_x = np.array(grp_mean.index)\n",
    "            grp_mean = np.array(grp_mean).flatten()\n",
    "            grp_std = np.array(grp_df.std()).flatten()\n",
    "            #print(len(grp_x), len(grp_mean), len(grp_std))\n",
    "            #print(grp_x)\n",
    "            #print(grp_mean)\n",
    "            #print(grp_std)\n",
    "            ax.plot(grp_x, grp_mean, lw=3, color=c, label=ds_names_conv[ds_name] if jdx == 1 else None, marker=markers[idx], ms=12, ls=line_styles[jdx], markeredgewidth = 2, markeredgecolor = (.99, .99, .99, .9))\n",
    "            # ax.fill_between(grp_x, grp_mean - grp_std, grp_mean + grp_std, alpha=0.2, color=c,)\n",
    "            # plt.show()\n",
    "    ax.set_xlabel('bias strength')\n",
    "    ax.set_ylabel('stationary probability')\n",
    "    ax.grid(b=True, which='major', axis='y', linewidth=3, alpha=0.2, ls='--')\n",
    "    # ax.legend(loc='best')\n",
    "    ax.set_ylim([0,1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt_tools.save_n_crop(plots_dir + 'saturation_' + method + '.pdf')\n",
    "    plt_tools.plot_legend(ax, plots_dir + 'saturation_legend.pdf', close_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 25})\n",
    "for method in ['link_inseration', 'bias']:\n",
    "    print('Method:', method)\n",
    "    measure = 'add_top_block_links_fair' if method == 'link_inseration' else 'stat_dist_com_sum'\n",
    "    fig, ax = plt.subplots()    \n",
    "    for idx, (key, val) in enumerate(sorted(data_dict.iteritems(), key=operator.itemgetter(0), reverse=True)):\n",
    "        # fig, ax = plt.subplots()\n",
    "        ds_name = ds_names_conv[key]\n",
    "        df = val[val['bias-strength'] == bias_strength].copy()\n",
    "        df.drop('bias-strength', axis=1, inplace=True)\n",
    "        # print(df.columns)\n",
    "        df = df[['sample-size', measure]]\n",
    "        grp_df = df.groupby('sample-size')\n",
    "        grp_mean = grp_df.mean()\n",
    "        grp_std = grp_df.std()\n",
    "        grp_x = np.array(grp_mean.index)\n",
    "        grp_mean = np.array(grp_mean).flatten()\n",
    "        grp_std = np.array(grp_df.std()).flatten()\n",
    "        # print(len(grp_x), len(grp_mean), len(grp_std))\n",
    "        # print(grp_x)\n",
    "        # print(grp_mean)\n",
    "        # print(grp_std)\n",
    "        ax.plot(grp_x, grp_mean, lw=3, color=colors[idx], label=ds_name if jdx == 1 else None, marker=markers[idx], ms=12, ls=line_styles[1], markeredgewidth = 2, markeredgecolor = (.99, .99, .99, .9))\n",
    "        ax.fill_between(grp_x, grp_mean - grp_std, grp_mean + grp_std, alpha=0.2, color=colors[idx])\n",
    "            # plt.show()\n",
    "    ax.set_xlabel('sample-size')\n",
    "    ax.set_ylabel('stationary probability')\n",
    "    ax.set_ylim([0,.55])\n",
    "    ax.grid(b=True, which='major', axis='y', linewidth=3, alpha=0.2, ls='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt_tools.save_n_crop(plots_dir + 'stat_dist_abs_'+ method + '_bs' + str(\"%.0f\" % bias_strength).rjust(4, '0') + '.pdf')\n",
    "    plt_tools.plot_legend(ax,plots_dir + 'stat_dist_abs_'+ method + '_legend.pdf', close_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for method in ['link_inseration', 'bias']:\n",
    "    print('Method:', method)\n",
    "    measure = 'add_top_block_links_fair' if method == 'link_inseration' else 'stat_dist_com_sum'\n",
    "    fig, ax = plt.subplots()\n",
    "    axins = None\n",
    "    if method == 'link_inseration':\n",
    "        pass\n",
    "        #axins = zoomed_inset_axes(ax, 2.5, loc=2)\n",
    "        #axins.set_ylim([0,2.])\n",
    "        #axins.set_xlim([0.05, .2])\n",
    "    for idx, (key, val) in enumerate(sorted(data_dict.iteritems(), key=operator.itemgetter(0), reverse=True)):\n",
    "        # fig, ax = plt.subplots()\n",
    "        ds_name = ds_names_conv[key]\n",
    "        df = val[val['bias-strength'] == bias_strength].copy()\n",
    "        df.drop('bias-strength', axis=1, inplace=True)\n",
    "        # print(df.columns)\n",
    "        df = df[['sample-size', measure, 'orig_stat_dist_sum']]\n",
    "        df['relative_stat'] = df[measure] / df['orig_stat_dist_sum']\n",
    "        df.drop([measure, 'orig_stat_dist_sum'], axis=1, inplace=True)\n",
    "        grp_df = df.groupby('sample-size')\n",
    "        grp_mean = grp_df.mean()\n",
    "        grp_std = grp_df.std()\n",
    "        grp_x = np.array(grp_mean.index)\n",
    "        grp_mean = np.array(grp_mean).flatten()\n",
    "        grp_std = np.array(grp_df.std()).flatten()\n",
    "        # print(len(grp_x), len(grp_mean), len(grp_std))\n",
    "        # print(grp_x)\n",
    "        # print(grp_mean)\n",
    "        # print(grp_std)\n",
    "        ax.plot(grp_x, grp_mean, lw=3, color=colors[idx], label=ds_name if jdx == 1 else None, marker=markers[idx], ms=12, ls=line_styles[1], markeredgewidth = 2, markeredgecolor = (.99, .99, .99, .9))\n",
    "        ax.fill_between(grp_x, grp_mean - grp_std, grp_mean + grp_std, alpha=0.2, interpolate=True, color=colors[idx])\n",
    "            # plt.show()\n",
    "        if axins is not None:\n",
    "            axins.plot(grp_x, grp_mean, lw=3, color=colors[idx], label=ds_name if jdx == 1 else None, marker=markers[idx], ms=12, ls=line_styles[1], markeredgewidth = 2, markeredgecolor = (.99, .99, .99, .9))\n",
    "            axins.fill_between(grp_x, grp_mean - grp_std, grp_mean + grp_std, alpha=0.2, interpolate=True, color=colors[idx])\n",
    "        \n",
    "    ax.set_xlabel('sample-size')\n",
    "    ax.set_ylabel('relative stat. increase')\n",
    "    # ax.set_ylim([0,.55])\n",
    "    ax.grid(b=True, which='major', axis='y', linewidth=3, alpha=0.2, ls='--')\n",
    "    ax.set_ylim([.1, 150])\n",
    "    ax.set_yscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt_tools.save_n_crop(plots_dir + 'stat_dist_rel_'+ method +  '_bs' + str(\"%.0f\" % bias_strength).rjust(4, '0') + '.pdf')\n",
    "    plt_tools.plot_legend(ax,plots_dir + 'stat_dist_rel_'+ method + '_legend.pdf', close_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
